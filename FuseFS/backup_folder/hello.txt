A sample text for testing:
Distributed training of graph neural networks (GNNs) has become a crucial technique for processing large graphs. Prevalent GNN frameworks are model-centric, necessitating the  transfer of massive graph vertex features to GNN models,  which leads to a significant communication bottleneck. Recognizing that the model size is often significantly smaller than the feature size, we propose LeapGNN, a feature-centric  framework that reverses this paradigm by bringing GNN models to vertex features.  To make it truly effective, we first propose a micrograph-based training strategy that leverages  a refined structure to enhanced locality, combining with the model migration technique, to minimize remote feature retrieval. 